{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5da3a677",
   "metadata": {},
   "source": [
    "# K-means Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608db9f",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0098b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f8cc13",
   "metadata": {},
   "source": [
    "## Import counts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c51ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('...',sep='\\t')\n",
    "data=data.drop(['Strand','Length'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5894b8d",
   "metadata": {},
   "source": [
    "### Transformation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becaab65",
   "metadata": {},
   "source": [
    "First it shows the sample counts higher than two and remove the gens which accumulate less than six samples above \"lim_below\" variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_below=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb799bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=(data.to_numpy()[:,1:]>=lim_below)*1\n",
    "data['count']=dat.sum(axis=1)\n",
    "data=data[data['count']>=6]\n",
    "data=data.drop(['count'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c587a98",
   "metadata": {},
   "source": [
    "Then it's used log2 to tranform the data. Is it ok with this transformation or is it ncessary check out the variances behavior to choose other transformation/normalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled=data.drop(['GeneID'],axis=1)\n",
    "data_scaled[data_scaled.columns]=np.log2(data_scaled.to_numpy()+1)\n",
    "data_scaled.insert(0,'GeneID',data['GeneID'])\n",
    "data_scaled=data_scaled.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4fb44c",
   "metadata": {},
   "source": [
    "## K-means: search a optimal K value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73505e",
   "metadata": {},
   "source": [
    "In order to get the optimal k-value it was used the Elbow curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27499d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from numpy import cov\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1636f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_scaled.to_numpy()[:,2:].T ## Get the transpose matrix of the scaled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4831fc",
   "metadata": {},
   "source": [
    "Define a range with different k values from 1 to 50 in steps of two;\n",
    "then the clusters are calculated for every k value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf1870",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_cluster=50 \n",
    "Nc=range(1,N_cluster,2)\n",
    "kmeans = [KMeans(n_clusters=i) for i in Nc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace58c79",
   "metadata": {},
   "source": [
    "The idea is pick the k value which optimizes the square distances of samples to their closest cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb7aaf2",
   "metadata": {},
   "source": [
    "kmeans.fit().inertia is KMeans function's attribute that shows the sum of square distances of samples to their closest clusters. Then these are plot as a function of cluster number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1e0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost=[kmeans[i].fit(X).inertia_ for i in range(len(kmeans))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb26354",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Nc,cost)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Sum of Squared error - Cost')\n",
    "plt.title('Elbow Curve')\n",
    "plt.xlim(0,50)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1fdfc5",
   "metadata": {},
   "source": [
    "Once the optimal K value is chose, the kmeans is recalculated with said value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans=KMeans(n_clusters=\"optimal_k_value\").fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69461cad",
   "metadata": {},
   "source": [
    "Get the coordinates of clusters centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac85f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroides=kmeans.cluster_centers_.T ## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee941c77",
   "metadata": {},
   "source": [
    "Here I thinck is necessary standarize the new data. But i'm no sure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
